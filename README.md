# Tuition-log

# Day 1

# Git, GitHub, and Basic Version Control Concepts
# ğŸ“˜ Part 1: Core Concepts
## Git
Git is an open-source Version Control System (VCS) that helps developers manage and track changes in source code during software development.

## GitHub
GitHub is a web-based platform that hosts Git repositories. It enables collaboration, code sharing, and version tracking, allowing developers to work together on projects.

Development Flow

Program â Open Source â Git (VCS)


### ğŸ’¡ What is Computer Science?
Computer Science (CS) is an engineering field. Unlike subjects such as math that have single correct answers, CS involves finding **multiple possible solutions** to a problem. Often, the challenge is to **define the right question**, and then build the **most efficient solution** to solve it.

### â˜ï¸ Microsoft OneDrive
Microsoft OneDrive is a **cloud-supported storage system**. It is managed by **data centers** that consist of multiple **servers** providing users access to files anywhere, anytime.

---

## Part 2: Learning GitHub & Commands

### âš ï¸ Terminal Commands

| Command     | Description                   |
|-------------|-------------------------------|
| `cd`        | Change directory               |
| `mkdir`     | Create a new directory         |

### ğŸ” Git & GitHub Commands

| Command                    | Description                                           |
|----------------------------|-------------------------------------------------------|
| `git clone <url>`          | Clone a repository from GitHub to your local machine |
| `git add .`                | Add all new or changed files to staging              |
| `git commit -m "message"`  | Commit staged changes with a message                 |
| `git push`                 | Push your local commits to the GitHub repository     |

### ğŸ“š Key GitHub Terms

- **Repository (repo):** A space to store your code, documentation (like this README), and other files.
- **Upstream:** A GitHub repo that is not the original one you cloned or forked.
- **Fork:** A personal copy of a repo that lets you freely experiment with changes.
- **Branch:** A version of the codebase used to develop features, fix bugs, or experiment without affecting the main code.

---

# Day 2

## AI, Machine Learning (ML), and Deep Learning (DL)

### ğŸ” Definitions

- **AI (Artificial Intelligence):** Includes all technologies that mimic human learning, reasoning, and problem-solving.
- **ML (Machine Learning):** A subset of AI that uses data to learn patterns and make predictions.
- **DL (Deep Learning):** A further subset of ML that uses neural networks to learn automatically from large datasets.


### ğŸ¤– Machine Learning vs Deep Learning

| êµ¬ë¶„              | ë¨¸ì‹ ëŸ¬ë‹ (Machine Learning)                                         | ë”¥ëŸ¬ë‹ (Deep Learning)                                         |
|-------------------|---------------------------------------------------------------------|----------------------------------------------------------------|
| ì •ì˜              | ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•™ìŠµí•˜ëŠ” AI ê¸°ë²•                                  | ì‹ ê²½ë§(Neural Network) ê¸°ë°˜ì˜ í•™ìŠµ                             |
| íŠ¹ì§•              | ë°ì´í„°ì—ì„œ íŒ¨í„´ì„ ì°¾ì•„ ì˜ˆì¸¡                                          | ë‹¤ì¸µ ì‹ ê²½ë§ì„ ì‚¬ìš©í•˜ì—¬ ìë™ìœ¼ë¡œ íŠ¹ì§• ì¶”ì¶œ                      |
| ë°ì´í„° ì˜ì¡´ì„±     | â†“ ë‚®ìŒ                                                               | â†‘ ë†’ìŒ                                                         |
| í•™ìŠµ ì†ë„         | ë¹ ë¦„                                                                 | ëŠë¦¼                                                           |
| ëª¨ë¸ ì˜ˆì‹œ         | SVM, ëœë¤ í¬ë ˆìŠ¤íŠ¸, KNN, ì„ í˜• íšŒê·€, ë¡œì§€ìŠ¤í‹± íšŒê·€ ë“±                | CNN, RNN, LSTM, GAN, Transformer ë“±                            |
| ì‘ìš© ë¶„ì•¼         | ì¶”ì²œ ì‹œìŠ¤í…œ, ì§ˆë³‘ ì˜ˆì¸¡, ê¸ˆìœµ ëª¨ë¸ë§                                 | ì´ë¯¸ì§€ ì¸ì‹, ìŒì„± ì¸ì‹, ììœ¨ì£¼í–‰, ë²ˆì—­, ìƒì„± AI               |

---

## Supervised vs Unsupervised Learning

| êµ¬ë¶„              | ì§€ë„í•™ìŠµ (Supervised Learning)                                      | ë¹„ì§€ë„í•™ìŠµ (Unsupervised Learning)                             |
|-------------------|---------------------------------------------------------------------|----------------------------------------------------------------|
| ì •ì˜              | ì •ë‹µ(ë¼ë²¨)ì´ ìˆëŠ” ë°ì´í„°ë¥¼ í•™ìŠµ                                     | ì •ë‹µ(ë¼ë²¨) ì—†ì´ ë°ì´í„°ë¥¼ í•™ìŠµ                                  |
| ëª©ì               | ì…ë ¥ ë°ì´í„°ë¥¼ ë³´ê³  ì •ë‹µì„ ì˜ˆì¸¡                                      | ë°ì´í„°ì˜ ìˆ¨ê²¨ì§„ íŒ¨í„´ì„ ì°¾ìŒ                                    |
| ì…ë ¥ ë°ì´í„°       | (ì…ë ¥ê°’, ì •ë‹µ) ìŒì´ ì¡´ì¬                                            | ì…ë ¥ê°’ë§Œ ì¡´ì¬ (ì •ë‹µ ì—†ìŒ)                                     |
| ì¶œë ¥ ê°’           | íŠ¹ì • ë¼ë²¨(ë¶„ë¥˜) ë˜ëŠ” ìˆ˜ì¹˜ ê°’(íšŒê·€) ì˜ˆì¸¡                            | ê·¸ë£¹(í´ëŸ¬ìŠ¤í„°) í• ë‹¹ ë˜ëŠ” íŒ¨í„´ ë°œê²¬                            |
| ëŒ€í‘œ ëª¨ë¸         | KNN, SVM, ê²°ì • íŠ¸ë¦¬, ëœë¤ í¬ë ˆìŠ¤íŠ¸, ì„ í˜• íšŒê·€, ë¡œì§€ìŠ¤í‹± íšŒê·€, ì‹ ê²½ë§ ë“± | K-Means, DBSCAN, PCA, êµ°ì§‘ ë¶„ì„, ì—°ê´€ ê·œì¹™ ë¶„ì„ ë“±             |
| ì˜ˆì‹œ              | ìŠ¤íŒ¸ ë©”ì¼ ë¶„ë¥˜, ì†ê¸€ì”¨ ìˆ«ì ì¸ì‹, ê°€ê²© ì˜ˆì¸¡                         | ê³ ê° ì„¸ë¶„í™”, ì´ìƒ íƒì§€, ì¶”ì²œ ì‹œìŠ¤í…œ                            |

---

## Numpy
ë‹¤ì°¨ì› ë°°ì—´(Matrix)ì˜ ë¹ ë¥¸ ì—°ì‚°

## Pandas
ë°ì´í„°ì— ëŒ€í•œ í‘œ í˜•ì‹ì˜ í‘œí˜„

## Matplotlib
ë°ì´í„° ê·¸ë˜í”„ ì‹œê°í™” ì²˜ë¦¬

---

# DAY 3

## Boxplot

```python
import matplotlib.pyplot as plt
import numpy as np

np.random.seed(10)
data = np.random.randn(50) * 10  # í‰ê·  0, í‘œì¤€í¸ì°¨ 10ì„ ë”°ë¥´ëŠ” ì •ê·œë¶„í¬ ë°ì´í„°
data = np.append(data, [50, -40])  # ì´ìƒì¹˜ ì¶”ê°€

# ë°•ìŠ¤í”Œë¡¯ ê·¸ë¦¬ê¸° (ì´ìƒì¹˜ í‘œì‹œ)
plt.boxplot(data)

# ì œëª© ë° ë¼ë²¨ ì¶”ê°€
plt.title("Box Plot with Outliers")
plt.ylabel("Value")
plt.show()
```
## How to translate a boxplot

# ğŸ“¦ Boxplot Interpretation

| Term | Description |
|:-----|:------------|
| **Minimum** | Position 1.5 IQR below the first quartile (Q1) |
| **First Quartile (Q1)** | Marks the 25% position at the bottom of the box |
| **Second Quartile (Q2)** | Median represented by the line inside the box, indicating 50% position |
| **Third Quartile (Q3)** | Marks the 75% position at the top of the box |
| **Maximum** | Position 1.5 IQR above the third quartile (Q3) |
| **Interquartile Range (IQR)** | The range between Q1 and Q3 |
| **Whisker** | Extends from the box to indicate the range of the data, up to the smallest and largest values within 1.5 IQR |
| **Outlier** | Data points beyond the minimum and maximum; if any exist, they are plotted beyond the whiskers |

![image](https://github.com/user-attachments/assets/cb717364-0953-4395-a32e-e450d6ac82f8)

## Iris Data set
ğŸŒ¸ Iris Dataset and KNN Algorithm
ğŸ“˜ Part 1: Iris Dataset
ğŸŒ¼ What is the Iris Dataset?
The Iris dataset is a famous dataset introduced by statistician Ronald Fisher in 1936.
It is commonly used for testing machine learning models and data analysis.

Sepal Length (cm) | Sepal Width (cm) | Petal Length (cm) | Petal Width (cm) | Species
5.1 | 3.5 | 1.4 | 0.2 | setosa
4.9 | 3.0 | 1.4 | 0.2 | setosa
4.7 | 3.2 | 1.3 | 0.2 | setosa
4.6 | 3.1 | 1.5 | 0.2 | setosa
5.0 | 3.6 | 1.4 | 0.2 | set

# ğŸ“˜ Part 2: K-Nearest Neighbors (KNN)
# ğŸ¤” What is KNN?
K-Nearest Neighbors (KNN) is a simple and widely used machine learning algorithm.
It classifies new data points based on the labels of the K closest data points.

# ğŸ’¡ How KNN Works:
When a new data point is given, find the K nearest data points in the existing dataset.

Determine the most common class (species) among those K points.

Assign the new data point to that class.

# â„¹ï¸ Tip:

A small K (e.g., K=1) means the prediction is highly influenced by nearby points.
A larger K (e.g., K=10) smooths the decision boundary and follows broader trends.

# Formulas

## Standardization Formula: 

Z = (X - Î¼) / Ïƒ

X : Original data
Î¼ : Mean
Ïƒ : Standard Deviation

Distance Calculation (Euclidean Distance)

For data generalized to N dimensions, the distance between two points P1(xâ‚, xâ‚‚, ..., xâ‚™) and P2(yâ‚, yâ‚‚, ..., yâ‚™):

In 2 dimensions:

d(Pâ‚, Pâ‚‚) = âˆš((xâ‚ - xâ‚‚)Â² + (yâ‚ - yâ‚‚)Â²)

In N dimensions:

d(Pâ‚, Pâ‚‚) = âˆš(âˆ‘ (i=1 to n) (xáµ¢ - yáµ¢)Â²)

